import csv
import os
import sys
import random
import json
import time
import urllib.request
import urllib.error
import concurrent.futures
from datetime import datetime

TARGET_COUNT = 15
OUTPUT_FILE = "quotes.csv"
MAX_WORKERS = 3
REQUEST_TIMEOUT = 10
API_SOURCES = [
    {
        "name": "ä¸€è¨€ï¼ˆå®˜æ–¹ï¼‰",
        "url": "https://v1.hitokoto.cn/",
        "params": {"c": ["i", "l", "k"], "encode": "json", "min_length": 5, "max_length": 30},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€ï¼ˆå›½é™…ç‰ˆï¼‰",
        "url": "https://international.v1.hitokoto.cn/",
        "params": {"c": ["i", "l", "k"], "encode": "json", "min_length": 5, "max_length": 30},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€ï¼ˆCNé•œåƒï¼‰",
        "url": "https://cn.hitokoto.cn/",
        "params": {"c": ["i", "l", "k"], "encode": "json", "min_length": 5, "max_length": 30},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€ï¼ˆå¤‡ç”¨åŸŸåï¼‰",
        "url": "https://sentence-api.qpchan.com/",
        "params": {"c": ["i", "l", "k"], "encode": "json", "min_length": 5, "max_length": 30},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€ï¼ˆPHPç‰ˆï¼‰",
        "url": "https://hitokoto.cn/api.php",
        "params": {"c": "i", "encode": "json"},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€è¯—è¯",
        "url": "https://v1.hitokoto.cn/",
        "params": {"c": "k", "encode": "json"},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€æ–‡å­¦",
        "url": "https://v1.hitokoto.cn/",
        "params": {"c": "l", "encode": "json"},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä¸€è¨€æ–‡è¨€",
        "url": "https://v1.hitokoto.cn/",
        "params": {"c": "d", "encode": "json"},
        "parser": lambda data: {"text": data.get("hitokoto", "").strip(), "author": data.get("from", "ä½šå").strip()}
    },
    {
        "name": "ä»Šæ—¥è¯—è¯",
        "url": "https://v2.jinrishici.com/one.json",
        "params": {},
        "parser": lambda data: {"text": data.get("data", {}).get("content", "").strip(), "author": data.get("data", {}).get("origin", {}).get("author", "ä½šå").strip()}
    },
    {
        "name": "å¤è¯—è¯API",
        "url": "https://api.gushi.ci/all.json",
        "params": {},
        "parser": lambda data: {"text": data[0].get("content", "").strip() if isinstance(data, list) and len(data) > 0 else "", "author": data[0].get("origin", {}).get("author", "ä½šå").strip() if isinstance(data, list) and len(data) > 0 else "ä½šå"}
    },
    {
        "name": "çˆ±è¯å»ºè¯—è¯",
        "url": "https://ciapi.xygeng.cn/one",
        "params": {},
        "parser": lambda data: {"text": data.get("content", "").strip(), "author": data.get("author", "").strip() if data.get("author") else "ä½šå"}
    },
    {
        "name": "éšæœºå¥å­",
        "url": "https://api.xygeng.cn/one",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": data.get("author", "ä½šå").strip()}
    },
    {
        "name": "å¥å­è¿·API",
        "url": "https://api.juzimi.com/api/random",
        "params": {},
        "parser": lambda data: {"text": data.get("content", "").strip(), "author": data.get("author", "å¥å­è¿·").strip()}
    },
    {
        "name": "ä¸€è¨€ä»£ç†",
        "url": "https://api.vvhan.com/api/ä¸€è¨€",
        "params": {},
        "parser": lambda data: {"text": data.get("data", {}).get("hitokoto", "").strip(), "author": data.get("data", {}).get("from", "ä½šå").strip()}
    },
    {
        "name": "åŠ±å¿—åè¨€",
        "url": "https://api.oick.cn/dutang/api.php",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": data.get("author", "ä½šå").strip()}
    },
    {
        "name": "åäººåè¨€",
        "url": "https://api.oick.cn/mingyan/api.php",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": data.get("author", "ä½šå").strip()}
    },
    {
        "name": "å¿ƒçµé¸¡æ±¤",
        "url": "https://api.oick.cn/yulu/api.php",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": data.get("author", "ä½šå").strip()}
    },
    {
        "name": "æ–‡è‰ºå¥å­",
        "url": "https://api.oick.cn/wenyi/api.php",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": data.get("author", "ä½šå").strip()}
    },
    {
        "name": "éšæœºæƒ…è¯",
        "url": "https://api.uomg.com/api/rand.qinghua",
        "params": {},
        "parser": lambda data: {"text": data.get("text", "").strip(), "author": "æƒ…è¯API"}
    },
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def log(message, type='info'):
    timestamp = datetime.å½“å‰().strftime("%H:%M:%S")
    if type == 'error':
        print(f"::error::{message}")
    elif type == 'warning':
        print(f"::warning::{message}")
    else:
        print(f"[{timestamp}] {message}")

def load_existing_quotes():
    """
    è¯»å–ç°æœ‰çš„ CSV æ–‡ä»¶
    """
    existing_set = set()
    existing_rows = []
    if not os.path.exists(OUTPUT_FILE):
        log(f"ğŸ“ æ–‡ä»¶ {OUTPUT_FILE} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶", 'info')
        return existing_set, existing_rows
    try:
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f, fieldnames=['author', 'text'])
            for row in reader:
                text = row.get('text', '').strip()
                author = row.get('author', '').strip()
                if text == 'text' and author == 'author':
                    continue
                if text:
                    unique_key = f"{text}-{author}"
                    existing_set.add(unique_key)
                    existing_rows.append({'author': author, 'text': text})   
        log(f"ğŸ“š å·²åŠ è½½ {len(existing_rows)} æ¡å†å²è¯­å½•", 'info')
    except Exception as e:
        log(f"âš ï¸ è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶", 'warning')
    return existing_set, existing_rows

def prune_old_quotes(existing_rows, count_to_remove):
    """
    éšæœºåˆ é™¤æŒ‡å®šæ•°é‡çš„æ—§è¯­å½•
    """
    current_count = len(existing_rows)
    if current_count <= count_to_remove:
        log(f"âš ï¸ å½“å‰è¯­å½•åªæœ‰ {current_count} æ¡ï¼Œå°‘äºæˆ–ç­‰äºè¦åˆ é™¤çš„ {count_to_remove} æ¡ï¼Œä¸æ¸…ç©ºï¼Œä¿ç•™å…¨éƒ¨ã€‚", 'warning')
        return existing_rows
    log(f"âœ‚ï¸ æ­£åœ¨éšæœºåˆ é™¤ {count_to_remove} æ¡æ—§è¯­å½•...", 'info')
    random.shuffle(existing_rows)
    kept_rows = existing_rows[:current_count - count_to_remove]
    log(f"ğŸ“‰ åˆ é™¤å®Œæ¯•ï¼Œå‰©ä½™ {len(kept_rows)} æ¡å†å²è¯­å½•", 'info')
    return kept_rows

def fetch_one_quote(source_index=0):
    """
    ä»æŒ‡å®šç´¢å¼•çš„ API æºè·å–ä¸€æ¡è¯­å½•ï¼Œå¤±è´¥åˆ™å°è¯•ä¸‹ä¸€ä¸ªæº
    """
    for i in range(source_index, len(API_SOURCES)):
        source = API_SOURCES[i]
        try:
            params_str = "&".join([f"{k}={v}" for k, v in source["params"].items()])
            url = f"{source['url']}?{params_str}" if params_str else source['url']
            req = urllib.request.Request(url, headers=HEADERS)
            with urllib.request.urlopen(req, timeout=REQUEST_TIMEOUT) as response:
                data = json.loads(response.read().decode('utf-8'))
                parsed = source["parser"](data)
                text = parsed.get("text", "")
                author = parsed.get("author", "ä½šå")
                if text:
                    return {'text': text, 'author': author}
        except Exception as e:
            pass
    return None

def fetch_new_quotes(count, existing_set):
    """
    è·å–æ–°çš„è¯­å½•
    """
    new_quotes = []
    consecutive_failures = 0
    MAX_FAILURES = 20
    log(f"ğŸš€ å¼€å§‹è·å– {count} æ¡æ–°è¯­å½•...", 'info')
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        while len(new_quotes) < count:
            needed = count - len(new_quotes)
            batch_size = min(needed, MAX_WORKERS * 2)
            source_index = random.randint(0, len(API_SOURCES) - 1)
            futures = [executor.submit(fetch_one_quote, source_index) for _ in range(batch_size)]
            round_success = 0
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    unique_key = f"{result['text']}-{result['author']}"
                    if unique_key not in existing_set:
                        new_keys = {f"{q['text']}-{q['author']}" for q in new_quotes}
                        if unique_key not in new_keys:
                            existing_set.add(unique_key)
                            new_quotes.append(result)
                            round_success += 1
                            sys.stdout.write(f"\r   è¿›åº¦: {len(new_quotes)}/{count}")
                            sys.stdout.flush()
            if round_success == 0:
                consecutive_failures += 1
                log(f"âš ï¸ ç¬¬ {consecutive_failures} æ¬¡å°è¯•æœªè·å–åˆ°æ–°æ•°æ®", 'warning')
            else:
                consecutive_failures = 0
            if consecutive_failures >= MAX_FAILURES:
                log(f"âŒ è¿ç»­ {MAX_FAILURES} æ¬¡å¤±è´¥ï¼Œç»ˆæ­¢è·å–", 'error')
                break
    elapsed = time.time() - start_time
    print()
    log(f"âœ… è·å–å®Œæˆï¼æ–°å¢ {len(new_quotes)} æ¡ï¼Œè€—æ—¶: {elapsed:.2f} ç§’", 'info')
    return new_quotes

def rewrite_csv(all_quotes):
    """
    è¦†ç›–å†™å…¥ CSV æ–‡ä»¶
    """
    print("::group::ğŸ’¾ é‡å†™ CSV æ–‡ä»¶")
    try:
        with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['author', 'text'])
            writer.writerows(all_quotes)
        print(f"âœ… æ–‡ä»¶å·²æ›´æ–°ï¼ˆæ— Headerï¼‰ï¼Œå½“å‰æ€»æ¡æ•°: {len(all_quotes)}")
        print("::endgroup::")
        return True
    except Exception as e:
        log(f"ä¿å­˜å¤±è´¥: {e}", 'error')
        return False

def generate_summary(new_quotes, total_count):
    summary_path = os.environ.get('GITHUB_STEP_SUMMARY')
    if not summary_path:
        return
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("# ğŸ“… æ¯æ—¥è¯­å½•æ›´æ–°æŠ¥å‘Š\n\n")
        f.write(f"**â° æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} \n\n")
        f.write(f"**ğŸ†• ä»Šæ—¥æ–°å¢**: `{len(new_quotes)}` æ¡ \n\n")
        f.write(f"**ğŸ“š æ€»è®¡**: `{total_count}` æ¡ \n\n")
        f.write("### ğŸ² ä»Šæ—¥æ–°å¢é¢„è§ˆ\n")
        f.write("| å†…å®¹ | å‡ºå¤„ |\n")
        f.write("| :--- | :--- |\n")
        for q in new_quotes[:min(5, len(new_quotes))]:
            safe_text = q['text'].replace('|', '\\|')
            safe_author = q['author'].replace('|', '\\|')
            f.write(f"| {safe_text} | {safe_author} |\n")

if __name__ == "__main__":
    start_time = time.time()
    
    try:
        existing_set, existing_rows = load_existing_quotes()
        if len(existing_rows) >= TARGET_COUNT: 
            existing_rows = prune_old_quotes(existing_rows, TARGET_COUNT)
            existing_set = {f"{row['text']}-{row['author']}" for row in existing_rows}
        new_quotes = fetch_new_quotes(TARGET_COUNT, existing_set)
        if len(new_quotes) > 0:
            final_list = existing_rows + new_quotes
            if rewrite_csv(final_list):
                generate_summary(new_quotes, len(final_list))
                log("ğŸ‰ ä»»åŠ¡å®Œæˆï¼", 'info')
            else:
                sys.exit(1)
        else:
            log("âš ï¸ æ²¡æœ‰è·å–åˆ°æ–°è¯­å½•ï¼Œæ–‡ä»¶ä¿æŒä¸å˜", 'warning') 
    except Exception as e:
        log(f"ä¸¥é‡é”™è¯¯: {e}", 'error')
        sys.exit(1)
